<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Python & Lenguaje Natural - Cat√°logo de Tareas</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        /* Hero Section */
        .hero {
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.9) 0%, rgba(118, 75, 162, 0.9) 100%);
            color: white;
            padding: 100px 20px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .hero::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: url('data:image/svg+xml,<svg width="100" height="100" xmlns="http://www.w3.org/2000/svg"><text x="10" y="50" font-size="40" opacity="0.1" fill="white">{"{ }"}</text></svg>');
            animation: float 20s linear infinite;
        }

        @keyframes float {
            from { transform: translateY(0); }
            to { transform: translateY(-100px); }
        }

        .hero-content {
            position: relative;
            z-index: 1;
            max-width: 800px;
            margin: 0 auto;
        }

        .hero h1 {
            font-size: 3.5rem;
            margin-bottom: 20px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            animation: fadeInDown 1s ease-out;
        }

        .hero p {
            font-size: 1.3rem;
            margin-bottom: 30px;
            animation: fadeInUp 1s ease-out;
        }

        @keyframes fadeInDown {
            from {
                opacity: 0;
                transform: translateY(-30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Container */
        .container {
            max-width: 1200px;
            margin: -50px auto 50px;
            padding: 0 20px;
            position: relative;
            z-index: 2;
        }

        /* Grid de Cards */
        .cards-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            padding: 20px 0;
        }

        /* Card Styles */
        .card {
            background: white;
            border-radius: 15px;
            overflow: hidden;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            animation: fadeIn 0.6s ease-out forwards;
            opacity: 0;
        }

        .card:nth-child(1) { animation-delay: 0.1s; }
        .card:nth-child(2) { animation-delay: 0.2s; }
        .card:nth-child(3) { animation-delay: 0.3s; }
        .card:nth-child(4) { animation-delay: 0.4s; }
        .card:nth-child(5) { animation-delay: 0.5s; }
        .card:nth-child(6) { animation-delay: 0.6s; }

        @keyframes fadeIn {
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .card:hover {
            transform: translateY(-10px);
            box-shadow: 0 15px 40px rgba(0,0,0,0.3);
        }

        .card-image {
            width: 100%;
            height: 200px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 4rem;
            color: white;
            position: relative;
            overflow: hidden;
        }

        .card-image::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
            animation: pulse 3s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }

        .card-content {
            padding: 25px;
        }

        .card-title {
            font-size: 1.5rem;
            color: #333;
            margin-bottom: 15px;
            font-weight: 600;
        }

        .card-description {
            color: #666;
            line-height: 1.6;
            margin-bottom: 20px;
            font-size: 0.95rem;
        }

        .download-btn {
            display: inline-block;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 12px 30px;
            border-radius: 25px;
            text-decoration: none;
            font-weight: 600;
            transition: all 0.3s ease;
            border: none;
            cursor: pointer;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        }

        .download-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
        }

        /* Responsive */
        @media (max-width: 768px) {
            .hero h1 {
                font-size: 2.5rem;
            }

            .hero p {
                font-size: 1.1rem;
            }

            .cards-grid {
                grid-template-columns: 1fr;
                gap: 20px;
            }

            .container {
                margin-top: -30px;
            }
        }

        @media (max-width: 480px) {
            .hero {
                padding: 60px 15px;
            }

            .hero h1 {
                font-size: 2rem;
            }

            .card-content {
                padding: 20px;
            }

            .card-title {
                font-size: 1.3rem;
            }
        }
    </style>
</head>
<body>
    <!-- Hero Section -->
    <section class="hero">
        <div class="hero-content">
            <h1>üêç Python & Lenguaje Natural</h1>
            <p>Colecci√≥n de herramientas para procesamiento de lenguaje natural con Python</p>
        </div>
    </section>

    <!-- Container con Cards -->
    <div class="container">
        <div class="cards-grid">
            <!-- Card 1: Tokenizar -->
            <div class="card">
                <div class="card-image">
                    üî§
                </div>
                <div class="card-content">
                    <h3 class="card-title">Tokenizar</h3>
                    <p class="card-description">
                        Divide textos en tokens individuales (palabras, caracteres o frases). Ideal para an√°lisis detallado de contenido textual.
                    </p>
                    <a href="tokenizar.py"class="download-btn">Descargar codigo.py</a>
                </div>
            </div>

            <!-- Card 2: Longitud de Palabras -->
            <div class="card">
                <div class="card-image">
                    üìè
                </div>
                <div class="card-content">
                    <h3 class="card-title">Longitud de Palabras</h3>
                    <p class="card-description">
                        Calcula y analiza la longitud de palabras en un texto. √ötil para estad√≠sticas ling√º√≠sticas y an√°lisis de complejidad.
                    </p>
                    <a href="longitud_palabras.py"class="download-btn">Descargar codigo.py</a>
                </div>
            </div>

            <!-- Card 3: Contar Palabras -->
            <div class="card">
                <div class="card-image">
                    üî¢
                </div>
                <div class="card-content">
                    <h3 class="card-title">Contar Palabras</h3>
                    <p class="card-description">
                        Cuenta la frecuencia de palabras en un texto. Perfecto para identificar t√©rminos m√°s utilizados y patrones de lenguaje.
                    </p>
                    <a href="contar_palabras.py"class="download-btn">Descargar codigo.py</a>                </div>
            </div>

            <!-- Card 4: An√°lisis de Sentimiento -->
            <div class="card">
                <div class="card-image">
                    üòä
                </div>
                <div class="card-content">
                    <h3 class="card-title">An√°lisis de Sentimiento</h3>
                    <p class="card-description">
                        Determina la polaridad emocional de un texto (positivo, negativo o neutral). Esencial para an√°lisis de opiniones.
                    </p>
                    <a href="analisis_sentimiento.py"class="download-btn">Descargar codigo.py</a>
                </div>
            </div>

            <!-- Card 5: Eliminar Puntuaci√≥n -->
            <div class="card">
                <div class="card-image">
                    ‚úÇÔ∏è
                </div>
                <div class="card-content">
                    <h3 class="card-title">Eliminar Signos de Puntuaci√≥n</h3>
                    <p class="card-description">
                        Limpia textos removiendo signos de puntuaci√≥n. Preprocesamiento fundamental para an√°lisis de texto limpio.
                    </p>
                    <a href="eliminar_puntuacion.py"class="download-btn">Descargar codigo.py</a>
                </div>
            </div>
        </div>
    </div>

    <script>
        function downloadCode(taskType) {
            let code = '';
            let filename = '';

            switch(taskType) {
                case 'tokenizar':
                    filename = 'tokenizar.py';
                    code = `# Tokenizaci√≥n de texto
import nltk
from nltk.tokenize import word_tokenize

# Aseg√∫rate de tener los recursos necesarios
# nltk.download('punkt')

def tokenizar_texto(texto):
    """
    Tokeniza un texto en palabras individuales.
    
    Args:
        texto (str): Texto a tokenizar
    
    Returns:
        list: Lista de tokens
    """
    tokens = word_tokenize(texto, language='spanish')
    return tokens

# Ejemplo de uso
if __name__ == "__main__":
    texto = "Python es un lenguaje de programaci√≥n incre√≠ble."
    tokens = tokenizar_texto(texto)
    print("Tokens:", tokens)
    print(f"Total de tokens: {len(tokens)}")`;
                    break;

                case 'longitud':
                    filename = 'longitud_palabras.py';
                    code = `# An√°lisis de longitud de palabras

def analizar_longitud_palabras(texto):
    """
    Analiza la longitud de las palabras en un texto.
    
    Args:
        texto (str): Texto a analizar
    
    Returns:
        dict: Estad√≠sticas de longitud de palabras
    """
    palabras = texto.split()
    longitudes = [len(palabra) for palabra in palabras]
    
    if not longitudes:
        return None
    
    estadisticas = {
        'total_palabras': len(palabras),
        'longitud_promedio': sum(longitudes) / len(longitudes),
        'palabra_mas_corta': min(longitudes),
        'palabra_mas_larga': max(longitudes),
        'longitudes': dict(zip(palabras, longitudes))
    }
    
    return estadisticas

# Ejemplo de uso
if __name__ == "__main__":
    texto = "Python facilita el procesamiento de lenguaje natural"
    stats = analizar_longitud_palabras(texto)
    print("Estad√≠sticas:", stats)`;
                    break;

                case 'contar':
                    filename = 'contar_palabras.py';
                    code = `# Contador de frecuencia de palabras
from collections import Counter
import re

def contar_palabras(texto, top_n=10):
    """
    Cuenta la frecuencia de palabras en un texto.
    
    Args:
        texto (str): Texto a analizar
        top_n (int): N√∫mero de palabras m√°s frecuentes a retornar
    
    Returns:
        Counter: Frecuencia de palabras
    """
    # Convertir a min√∫sculas y eliminar caracteres especiales
    texto_limpio = re.sub(r'[^\\w\\s]', '', texto.lower())
    palabras = texto_limpio.split()
    
    # Contar frecuencia
    frecuencia = Counter(palabras)
    
    return frecuencia.most_common(top_n)

# Ejemplo de uso
if __name__ == "__main__":
    texto = "Python es genial. Python es poderoso. Python es vers√°til."
    resultado = contar_palabras(texto)
    print("Palabras m√°s frecuentes:")
    for palabra, freq in resultado:
        print(f"{palabra}: {freq}")`;
                    break;

                case 'sentimiento':
                    filename = 'analisis_sentimiento.py';
                    code = `# An√°lisis de sentimiento
from textblob import TextBlob

def analizar_sentimiento(texto):
    """
    Analiza el sentimiento de un texto.
    
    Args:
        texto (str): Texto a analizar
    
    Returns:
        dict: Polaridad y subjetividad del texto
    """
    blob = TextBlob(texto)
    
    # Polaridad: -1 (negativo) a 1 (positivo)
    polaridad = blob.sentiment.polarity
    
    # Subjetividad: 0 (objetivo) a 1 (subjetivo)
    subjetividad = blob.sentiment.subjectivity
    
    # Clasificar sentimiento
    if polaridad > 0.1:
        clasificacion = "Positivo"
    elif polaridad < -0.1:
        clasificacion = "Negativo"
    else:
        clasificacion = "Neutral"
    
    return {
        'texto': texto,
        'polaridad': polaridad,
        'subjetividad': subjetividad,
        'clasificacion': clasificacion
    }

# Ejemplo de uso
if __name__ == "__main__":
    texto = "Me encanta programar en Python, es fant√°stico!"
    resultado = analizar_sentimiento(texto)
    print("An√°lisis de sentimiento:", resultado)`;
                    break;

                case 'puntuacion':
                    filename = 'eliminar_puntuacion.py';
                    code = `# Eliminaci√≥n de signos de puntuaci√≥n
import string
import re

def eliminar_puntuacion(texto, metodo='string'):
    """
    Elimina signos de puntuaci√≥n de un texto.
    
    Args:
        texto (str): Texto a limpiar
        metodo (str): 'string' o 'regex'
    
    Returns:
        str: Texto sin puntuaci√≥n
    """
    if metodo == 'string':
        # Usar el m√≥dulo string
        translator = str.maketrans('', '', string.punctuation)
        texto_limpio = texto.translate(translator)
    
    elif metodo == 'regex':
        # Usar expresiones regulares
        texto_limpio = re.sub(r'[^\\w\\s]', '', texto)
    
    return texto_limpio

# Ejemplo de uso
if __name__ == "__main__":
    texto = "¬°Hola! ¬øC√≥mo est√°s? Python es genial, ¬øverdad?"
    
    print("Original:", texto)
    print("Sin puntuaci√≥n (string):", eliminar_puntuacion(texto, 'string'))
    print("Sin puntuaci√≥n (regex):", eliminar_puntuacion(texto, 'regex'))`;
                    break;
            }

            // Crear blob y descargar
            const blob = new Blob([code], { type: 'text/plain' });
            const url = window.URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            document.body.appendChild(a);
            a.click();
            window.URL.revokeObjectURL(url);
            document.body.removeChild(a);
        }
    </script>
</body>
</html>